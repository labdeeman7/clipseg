{"batch_size": 16, "optimizer": "torch.optim.AdamW", "lr": 0.001, "trainer": "experiment_setup.train_loop", "scorer": "experiment_setup.score", "model": "models.clipseg.CLIPDensePredT", "lr_scheduler": null, "T_max": 20000, "eta_min": 0.0001, "max_iterations": 20000, "val_interval": null, "dataset": "datasets.endovis.Endovis2017", "split_mode": "pascal_test", "split": "train", "mask": "text", "image_size": 352, "normalize": true, "pre_crop_image_size": ["sample", 1, 1.5], "aug": "1new", "mix": false, "prompt": "shuffle+", "norm_cond": true, "mix_text_min": 0.0, "out": 1, "extract_layers": [3, 7, 9], "reduce_dim": 64, "depth": 3, "fix_shift": false, "pretrained": true, "pretrained_path": "weights/clipseg_weights/rd64-uni-refined.pth", "save_checkpoint_iterations": true, "save_checkpoint_freq": 500, "log_freq": 100, "loss": "torch.nn.functional.binary_cross_entropy_with_logits", "amp": true, "name": "rd64-uni", "version": "ViT-B/16", "with_visual": false, "negative_prob": 0, "complex_trans_conv": true}